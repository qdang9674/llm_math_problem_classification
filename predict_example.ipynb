{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19a18d8e-edb2-4308-9d50-a06fd7e4bfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 02:35:26.501757: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-08 02:35:26.519397: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-08 02:35:26.538573: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-08 02:35:26.544415: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-08 02:35:26.559174: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-08 02:35:27.579719: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from prediction_library import model_predict\n",
    "from transformers import DistilBertTokenizer\n",
    "from transformers import TFDistilBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba62874e-6c9c-400b-b57a-bdfae1e6f0b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/nfs/ada/jbrook1/users/qdang1/Duong_LLM/output/run10/'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RUN = 'run10'\n",
    "CURRENT_DIR = os.getcwd()\n",
    "OUTPUT_DIR = CURRENT_DIR + '/output/' + RUN + '/'\n",
    "OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5bde8f0-b534-4e91-94c6-5e4381e0649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_input = ['Independent Trials: Hensel\\'s Lemma: A result in number theory that provides conditions under which a solution to a congruence modulo a prime power can be \"lifted\" to a solution modulo a higher power of the prime, using p-adic numbers.',\n",
    " 'Period Finding: Surface Area: The total area of all external faces of a three-dimensional object.',\n",
    " 'Definiteness: Hermitian matrices can be positive or negative definite/semidefinite, determining various properties in quadratic forms.: Least Common Multiple (LCM) in Parallel Computing: The smallest multiple shared by two or more numbers, computed efficiently across multiple processors to enhance performance.',\n",
    " \"Cross Product and Plane Normal: Recursive relationships in probability combinatorics often involve breaking down complex probability problems into simpler, smaller problems. The binomial theorem provides a formula for expanding expressions raised to a power, and Pascal's Triangle is a triangular array of numbers that provides coefficients for the binomial expansion, demonstrating recursive relationships in its construction.\",\n",
    " 'Volume Comparison of Solids: Inradius: The inradius of a triangle is the radius of the largest circle that fits inside the triangle, touching all three sides.',\n",
    " 'Ad Hominem: Magnitude (Modulus) for Complex Numbers: In polar coordinates, the magnitude (or modulus) of a complex number ( z = a + bi ) is the distance from the origin to the point ( (a, b) ) in the complex plane, calculated as ( |z| = a^2 + b^2 ).',\n",
    " \"Iterative Filtering: Lenstra's Elliptic Curve Method (ECM) is an algorithm used to factor integers by exploiting the group structure of elliptic curves over finite fields.\",\n",
    " 'Recurrence Relation: Hermite polynomials are a sequence of orthogonal polynomials defined by the recurrence relation: ( H_n+1(x) = 2xH_n(x) - 2nH_n-1(x) ), where ( H_0(x) = 1 ) and ( H_1(x) = 2x ).',\n",
    " 'Infinite Set of Prime Multiples: An adjacency matrix is a square matrix used to represent a graph, where each element indicates whether pairs of vertices are adjacent or not.',\n",
    " 'Successes and Failures: Defining the number of successful outcomes and failures in the population.: Least Common Multiple (LCM): The smallest positive integer divisible by each of the given integers.']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "567e732f-e082-4f8b-b50f-057cc523edb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qdang1/.conda/envs/tf2/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "2024-12-08 02:35:49.575221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22261 MB memory:  -> device: 0, name: Quadro RTX 6000, pci bus id: 0000:1b:00.0, compute capability: 7.5\n",
      "2024-12-08 02:35:49.577138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22261 MB memory:  -> device: 1, name: Quadro RTX 6000, pci bus id: 0000:1c:00.0, compute capability: 7.5\n",
      "2024-12-08 02:35:49.578843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 22261 MB memory:  -> device: 2, name: Quadro RTX 6000, pci bus id: 0000:1d:00.0, compute capability: 7.5\n",
      "2024-12-08 02:35:49.580287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 22261 MB memory:  -> device: 3, name: Quadro RTX 6000, pci bus id: 0000:1e:00.0, compute capability: 7.5\n",
      "2024-12-08 02:35:49.581530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 22261 MB memory:  -> device: 4, name: Quadro RTX 6000, pci bus id: 0000:3d:00.0, compute capability: 7.5\n",
      "2024-12-08 02:35:49.582736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 22261 MB memory:  -> device: 5, name: Quadro RTX 6000, pci bus id: 0000:3f:00.0, compute capability: 7.5\n",
      "2024-12-08 02:35:49.583917: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 22261 MB memory:  -> device: 6, name: Quadro RTX 6000, pci bus id: 0000:40:00.0, compute capability: 7.5\n",
      "2024-12-08 02:35:49.585113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 22261 MB memory:  -> device: 7, name: Quadro RTX 6000, pci bus id: 0000:41:00.0, compute capability: 7.5\n",
      "All model checkpoint layers were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFDistilBertForSequenceClassification were initialized from the model checkpoint at /nfs/ada/jbrook1/users/qdang1/Duong_LLM/output/run10/model0.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n",
      "Some layers from the model checkpoint at /nfs/ada/jbrook1/users/qdang1/Duong_LLM/output/run10/model1 were not used when initializing TFDistilBertForSequenceClassification: ['dropout_19']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at /nfs/ada/jbrook1/users/qdang1/Duong_LLM/output/run10/model1 and are newly initialized: ['dropout_39']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#load model\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', cache_dir=\"/nfs/ada/jbrook1/users/qdang1/temp/\")\n",
    "model_0 = TFDistilBertForSequenceClassification.from_pretrained(OUTPUT_DIR + 'model0')\n",
    "model_1 = TFDistilBertForSequenceClassification.from_pretrained(OUTPUT_DIR + 'model1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a03d668-dfdd-4c7e-ae5a-5299e959c20d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 7), dtype=float32, numpy=\n",
       "array([[ 2.4491534 , -3.0290937 , -2.0179863 , -3.4772308 , -4.837431  ,\n",
       "         5.745096  , -3.8200607 ],\n",
       "       [-1.1480278 , -2.841751  , -1.0351181 , -1.7649231 , -7.4964104 ,\n",
       "        -0.7178221 ,  5.365823  ],\n",
       "       [ 2.8868153 , -0.6158583 ,  8.182995  , -4.624798  , -7.8672853 ,\n",
       "        -2.9725523 , -3.8121486 ],\n",
       "       [ 0.4449039 ,  0.5100265 , -5.259001  ,  8.101575  , -8.932299  ,\n",
       "        -5.077175  , -1.9209414 ],\n",
       "       [-1.026739  , -4.48734   , -3.2931986 ,  5.868236  , -9.814299  ,\n",
       "        -4.52129   ,  4.2869787 ],\n",
       "       [ 4.711749  , -3.8651526 ,  0.31495833, -3.9192617 , -8.114265  ,\n",
       "        -5.3401113 ,  5.0782657 ],\n",
       "       [-1.30786   ,  1.4740833 ,  4.6308346 , -5.1816187 , -7.146197  ,\n",
       "         2.9575722 , -3.3251042 ],\n",
       "       [-2.7409763 ,  0.46972772,  5.374054  , -4.203752  , -6.4715385 ,\n",
       "         3.5643976 , -3.4890888 ],\n",
       "       [-3.4619823 , -2.2519834 , 12.974302  , -5.438378  , -8.249296  ,\n",
       "        -2.6655216 , -0.63025653],\n",
       "       [-2.6045866 , -5.2149773 , -1.0915589 , -4.324256  , -7.0790133 ,\n",
       "        11.555658  , -2.6810162 ]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = model_predict(example_input, tokenizer, model_0, model_1, return_label = False)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36855d02-b364-4e98-8e76-b53b68744eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 6, 2, 3, 3, 6, 2, 2, 2, 5])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = model_predict(example_input, tokenizer, model_0, model_1, return_label = True)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10791159-76fc-451a-bf69-6bec66dc63ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_mapping = {\n",
    "    'algebra': 0,\n",
    "    'polynomial_sequences_calculus': 1,\n",
    "    'number_theory': 2,\n",
    "    'geometry': 3,\n",
    "    'measurement': 4,\n",
    "    'probability_combinatorics': 5,\n",
    "    'comparison_reasoning': 6\n",
    "}\n",
    "\n",
    "inverted_map = {v: k for k, v in topic_mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2ba208a-9884-4f57-9163-72447572d958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'algebra',\n",
       " 1: 'polynomial_sequences_calculus',\n",
       " 2: 'number_theory',\n",
       " 3: 'geometry',\n",
       " 4: 'measurement',\n",
       " 5: 'probability_combinatorics',\n",
       " 6: 'comparison_reasoning'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_mapped = [inverted_map[i] for i in predict]\n",
    "predict_mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8fca91-6aab-4fef-9c47-a97cbdd860d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a4a5a5-b598-49fd-8e7a-491e94f4bf3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25fac36-ff5b-4333-8009-8dbedf76fa29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb27f9b1-1d4d-405e-9f41-3d9eb2671c8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158bde9a-8f11-4c9b-ae61-3d40867fb4c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31dc662-7fdd-4899-81ca-33d4d5fdc747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b77a207-a5f6-4937-a12c-1522c15e612e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
